{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the basic libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# imports for Natural Language  Processing\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import string\n",
    "import time\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from html.parser import HTMLParser\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import emoji\n",
    "from emoji import emojize\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "# Classification Models\n",
    "import xgboost\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "\n",
    "# Performance Evaluation\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pipelinehelper import PipelineHelper\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "# Import library for train test split\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "\n",
    "# Set plot style\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# Wordcloud\n",
    "from PIL import Image\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Resampling techniques\n",
    "from collections import Counter \n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be making use of a pipeline to build our classification models. This pipeline will vectorize the text data before fitting it to our chosen model.\n",
    "\n",
    "The following models will be considered:\n",
    "\n",
    "- Random forest\n",
    "- Naive Bayes\n",
    "- K nearest neighbors\n",
    "- Logistic regression\n",
    "- Support vector machine (SVM OR SVC)\n",
    "- Linear SVC\n",
    "- Xgboost\n",
    "- SGD Classifier\n",
    "- Adaboost\n",
    "- Decision tree\n",
    "\n",
    "### Train - Validation split\n",
    "\n",
    "Before we pass our data through our custom pipelines we have to split our train data into features and target variables. After this step we can split our train data into a train and validation set. This will allow us to evaluate our model performance and chose the best model to use for our submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate features and target variables\n",
    "X = df_tok['lemmatized']\n",
    "y = df_tok['sdg']\n",
    "\n",
    "# Create train and validation set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines\n",
    "\n",
    "Pipelines consist of 2 steps, vectorization and model fitting.\n",
    "\n",
    "Machines, unlike humans, cannot understand the raw text. Machines can only see numbers. Particularly, statistical techniques such as machine learning can only deal with numbers. Therefore, we need to convert our text into numbers.\n",
    "\n",
    "The TFIDF or Count vectorizer assigns word frequency scores that try to highlight words that are more interesting, e.g. frequent in a document but not across documents. The TfidfVectorizer will tokenize documents, learn the vocabulary and inverse document frequency weightings, and allow you to encode new documents. Another advantage of this method is that the resulting vectors are already scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(models, X_train: pd.DataFrame , y_train: pd.DataFrame, X_test: pd.DataFrame, y_test: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Lightweight script to test many models\n",
    "    Args:\n",
    "    :param X_train: training split\n",
    "    :param y_train: training target vector\n",
    "    :param X_test: test split\n",
    "    :param y_test: test target vector\n",
    "    Returns:\n",
    "        DataFrame of predictions\n",
    "    '''\n",
    "    \n",
    "    dfs = []\n",
    "    results = []\n",
    "    names = []\n",
    "    target_names = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15']\n",
    "\n",
    "    for name, model in models:\n",
    "        kfold = KFold(n_splits=5, shuffle=True) # splitting the data into kfolds\n",
    "        cv_results = cross_validate(model, X_train, y_train, cv=kfold)\n",
    "        clf = model.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(name)\n",
    "        print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "        print('F1_SCORE:', f1_score(y_test, y_pred, average= 'weighted'))\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        cm_train = pd.DataFrame(cm, index = target_names, columns = target_names)\n",
    "        # plotting the confusion matrix using heatmap\n",
    "        print('Confusion Matrix')\n",
    "        plt.figure(figsize=(10,5))\n",
    "        sns.heatmap(cm_train, annot=True)\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.ylabel('Actal Values')\n",
    "        plt.xlabel('Predicted Values')\n",
    "        plt.show()\n",
    "    \n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        this_df = pd.DataFrame(cv_results)\n",
    "        this_df['model'] = name\n",
    "        dfs.append(this_df)\n",
    "    final = pd.concat(dfs, ignore_index=True)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "2043299c89c8cd0b4d1a6f5cf4529bd58e6a4e0fe3181a25e0d328c821cdc5c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
